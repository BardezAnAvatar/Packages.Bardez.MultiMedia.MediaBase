Namespace layout:
	Data		(pixels, resize, etc.)
	Container 	(containers for wholeness of frames of data: avi, LibAV, etc.)
	Frame		(containers for data groups: Float audio, PCM audio, Image data, etc.)
	Management	(When to play what)
	Render		(accepts frames and renders them to video, audio, disk, etc.)


Design Model:
	Controller will hold a container
	Controller will hold a collection (collections) or RenderManagers
	Controller will pull data from container (in IMultimediaFrameBuffer) and pass into the RenderManagers.
	Controller will give access of the IMultimediaFrameStreamBuffers directly to RenderManagers
	Controller will expose metadata of the streams (from container) to indicate to its owner which
		stream is what, so that the owner can subscribe to events from Manager's RenderManagers
		(e.g.: two video streams, one subtitle, one video, could use a single renderer that layers.)
		(e.g.: one video stream could have two renderers attached [display, disk writer])
		(e.g.: 4 audio streams could have one renderer each simultaneously)
		(e.g.: 2 video streams could render side-by-side simultaneously)

	Container will expose metadata for channels such as renderable text to indicate available streams
	Container will expose "default" stream options
	Container will decode/return Frames to pass on to RenderManagement via IMultimediaFrameBuffer

	Frame will encompass a single set of data samples for rendering, returned from container into RenderManager into Renderers
	
	RenderManagers will expose an AttemptRender and a Render event.
	AttemptRender will be for Manager to pass in a timecode, at which point the render manager decides
		whether or not to render, when it pulls a frame from the StreamingFrameBuffer and raises the render
		event.
	Render event will connect to an actual renderer
	
	Renderer will attach to a render event. This will then react to the data submitted in the frame
		and render out to associated control, resource, etc.
	